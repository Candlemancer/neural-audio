<!DOCTYPE html>
<html>
<head>
	<title>Nerual Audio</title>
	<link rel="stylesheet" type="text/css" href="style.css">
</head>
<body>
	<div id="content">		
	<h1>
		An Algorithm for Identifying and Separating Musical Content and Style
	</h1>

	<p id="links">
		  <a href="https://github.com/Candlemancer/neural-audio" target="_blank">Github</a>
		| <a href="http://arxiv.org/abs/1508.06576" target="_blank">Research Paper</a>
		| <a href="https://github.com/jcjohnson/neural-style" target="_blank">Neural-Style</a> 
		| <a href="http://torch.ch/" target="_blank">Torch</a> 
	</p>
	<br>
	<br>

	<p id="teaser">
		This last August, a group of researchers based in Germany created 
		<a href="http://arxiv.org/abs/1508.06576">an algorithm</a>  
		that could read in two images and recreate content of one image with the style of the other. Soon thereafter, Justin Johnson created 
		<a href="https://github.com/jcjohnson/neural-style">
			an implementation
		</a> 
		of this algorithm in lua using the torch scientific computing framework. This is a continuation of that project, in which I'm attempting to use this algorithm to study audio data and see if some similar results can be obtained.
	</p>

	<div class="graphicDemo">
		<div class="artSet">
			<span class="helper"></span>
			<img class="artDemo" src="res/neural-style-examples/me.jpg">			
		</div>
		<div class="artSet">
			<span class="helper"></span>
			<img class="artDemo" src="res/neural-style-examples/chinese.jpg">			
		</div>
		<div class="artSet">
			<span class="helper"></span>
			<img class="artDemo" src="res/neural-style-examples/me_chinese.png">		
		</div>
	</div>

	<br>
	<br>

	<h2>What</h2>
	<p>
		My algorithm attempts to use the neural-style algorithm developed by Johnson as a black-box function to study audio data. To do this, I've created a set of functions that can encode a .mp3 file into a Torch tensor that represents each frequency sample as a weight with a value between 0 and 1. We then feed that representation into the neural network that fuels the image analysis and recombination, and take the resulting RGB image, strip off the extra color channels, upconvert the output weights into audible frequencies, and serialize the data into a .wav file.
	</p>
	<p>
		There is also a collection of utility functions that aid in analyzing the data through statistical methods, and rudimentary image processing via a smoothing function to make the output more palatable. 
	</p>

	<div class="graphicDemo">
		<div>
			<span class="helper"></span>
			<audio controls>
				<source src="res/input/clip/reggae.mp3" type="audio/mpeg">
				Your browser does not support the audio element.
			</audio>
		</div>
		<img class="icon" src="res/equal.png">
		<div>
			<img class="artDemo" src="res/output/img/reggae.png">
		</div>
	</div>


	<br>

	<h2>Why</h2>
	<p>
		It's long been believed that creating new art would be one of the hardest things to do algorithmically, but the above paper showed that it was at least possible to mimic the way that human art students began learning to create quality pieces, namely by drawing original objects in the style of other artists, or drawing common objects in their own style. 
	</p>
	<p>
		This algorithm attempts to replicate that with audio data, and investigate if it's possible to train the algorithm to create new pieces of music by combining the content of one piece with the style of another.
	</p>

	<div class="graphicDemo">
		<div>
			<span class="helper"></span>
			<img class="artDemo" src="res/output/img/sleep.png">
			<audio controls>
				<source src="res/input/clip/sleep.mp3" type="audio/mpeg">
				Your browser does not support the audio element.
			</audio>			
		</div>
		<img class="icon" src="res/plus.png">
		<div>
		<span class="helper"></span>
			<img class="artDemo" src="res/output/img/maid.png">
			<audio controls>
				<source src="res/input/clip/maid.mp3" type="audio/mpeg">
				Your browser does not support the audio element.
			</audio>	
		</div>
		<img class="icon" src="res/equal.png">
		<div>
			<span class="helper"></span>
			<img class="artDemo" src="res/output/combined/sleep_maid.png">
			<audio controls>
				<source src="res/output/wav/sleep_maid_smooth.mp3" type="audio/mpeg">
				Your browser does not support the audio element.
			</audio>			
		</div>
	</div>

	<br>

	<h2>Results</h2>
	<p>
		At the end of the day, the results are promising for further inquiry into this topic. The audio files generated by the algorithm are distinct, and choosing different style images can influence a piece of music towards a more flat or varied output, depending on the style image chosen. 
	</p>

	<div class="graphicDemo">
			<audio controls>
				<source src="res/output/wav/sleep_maid_smooth.mp3" type="audio/mpeg">
				Your browser does not support the audio element.
			</audio>
	</div>

	<p>
		Unfortunately, my methods end up losing a lot of detail in the audio data, particularly during the conversion from audio frequencies to RGB color values. When this lossiness is combined with the smoothing function used to remove the harsh noise, most audio clips come out sounding very similar. Future attempts should try encoding the image data in a format that permits a wider color depth to try and minimize this muffling effect. Users of this program can also adjust the smoothing width of the postprocessing function to try and recapture some of the lost details, though this generally leads to rougher-sounding tracks.
	</p>

	<div class="graphicDemo">
			<audio controls>
				<source src="res/output/wav/maid_gerudo.mp3" type="audio/mpeg">
				Your browser does not support the audio element.
			</audio>
	</div>

	<p>
		Drawbacks aside, this project was very much a success, and it's been interesting to see how an AI designed to solve one problem can be adapted for another. It's also been a great experience to learn about heavy-duty scientific computing in Lua, and I hope to continue my research in this topic.
	</p>

	</div>

</body>
</html>
